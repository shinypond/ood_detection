{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "from models import *\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def plot_hist(*args, bins=[100, 100], labels=['cifar10', 'svhn'], xlim=[0, 10]):\n",
    "    \n",
    "    if len(args) != len(bins) or len(args) != len(labels) or len(bins) != len(labels):\n",
    "        print('Oops! GRADS, BINS and LABELS must have the same length !')\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "    \n",
    "    in_dist_Grads = torch.tensor(args[0]).detach().cpu().numpy()\n",
    "    plt.hist(in_dist_Grads, bins=bins[0], density=True, alpha=0.9, color='black', label=labels[0])\n",
    "\n",
    "    for i in range(1, len(args)):\n",
    "        out_dist_Grads = torch.tensor(args[i]).detach().cpu().numpy()\n",
    "        plt.hist(out_dist_Grads, bins=bins[i], density=True, alpha=0.5, label=labels[i])\n",
    "    \n",
    "    plt.xlim(xlim[0], xlim[1])\n",
    "    plt.title(f'In-Dist : {labels[0]}  /  Out-Dist : {[labels[i] for i in range(1, len(args))]}')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def AUROC(*args, labels=['cifar10', 'svhn'], plot=True):    \n",
    "    in_dist_Grads = args[0]\n",
    "    out_dist_Grads = args[1]\n",
    "    combined = np.concatenate((in_dist_Grads, out_dist_Grads))\n",
    "    label_1 = np.ones(len(in_dist_Grads))\n",
    "    label_2 = np.zeros(len(out_dist_Grads))\n",
    "    label = np.concatenate((label_1, label_2))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(label, combined, pos_label=0)\n",
    "    #plot_roc_curve(fpr, tpr)\n",
    "    rocauc = metrics.auc(fpr, tpr)\n",
    "    title = f'In-dist : {labels[0]}  /  Out-dist : {labels[1]} \\n AUC for Gradient Norm is: {rocauc:.6f}'\n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(12, 9))\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.title(title)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    return rocauc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OPT():\n",
    "    def __init__(self, train_dist):\n",
    "        self.dataroot = '../data'\n",
    "        self.imageSize = 32\n",
    "        self.workers = 0\n",
    "        if train_dist == 'cifar10':\n",
    "            self.nc = 3\n",
    "        elif train_dist == 'fmnist':\n",
    "            self.nc = 1\n",
    "            \n",
    "            \n",
    "def TEST_loader(train_dist, target_dist, batch_size=100, shuffle=False, alpha_mode=None, alpha_value=1):\n",
    "    \n",
    "    \"\"\" Return test_loader for given 'train_dist' and 'target_dist' \"\"\"\n",
    "    \n",
    "    \"\"\" train_dist = 'cifar10' or 'fmnist' \"\"\"\n",
    "    \n",
    "    \"\"\" target_dist (In-Distribution or Out-of-Distribution)\n",
    "    \n",
    "            if train_dist is 'cifar10' (train), target_dist should be one of\n",
    "                    - cifar10 (test)\n",
    "                    - svhn (test)     \n",
    "                    - celeba (test)   \n",
    "                    - lsun (test)     \n",
    "                    - cifar100 (test) \n",
    "                    - mnist (test)    \n",
    "                    - fmnist (test)   \n",
    "                    - kmnist (test)   \n",
    "                    - omniglot (eval) \n",
    "                    - notmnist (small)\n",
    "                    - trafficsign\n",
    "                    - noise\n",
    "                    - constant\n",
    "            \n",
    "            if train_dist is 'fmnist' (train), target_dist should be one of\n",
    "                    - fmnist (test)\n",
    "                    - svhn (test)     \n",
    "                    - celeba (test)   \n",
    "                    - lsun (test)     \n",
    "                    - cifar10 (test)  \n",
    "                    - cifar100 (test) \n",
    "                    - mnist (test)    \n",
    "                    - kmnist (test)   \n",
    "                    - omniglot (eval) \n",
    "                    - notmnist (small)\n",
    "                    - noise\n",
    "                    - constant\n",
    "    \n",
    "    \"\"\"\n",
    "    def preprocess_alpha_mean(x):\n",
    "        x = x * 255\n",
    "        m = torch.mean(x, [1, 2], keepdim=True)\n",
    "        x = torch.clamp((x - m) * alpha_value + m, 0, 255) // 1\n",
    "        x = x / 255\n",
    "        return x\n",
    "    \n",
    "    def preprocess_alpha_zero(x):\n",
    "        x = x * 255\n",
    "        x = torch.clamp(x * alpha_value, 0, 255) // 1\n",
    "        x = x / 255\n",
    "        return x    \n",
    "    \n",
    "    if alpha_mode == 'mean':\n",
    "        preprocess_alpha = preprocess_alpha_mean\n",
    "        \n",
    "    elif alpha_mode == 'zero':\n",
    "        preprocess_alpha = preprocess_alpha_zero\n",
    "    \n",
    "    preprocess1 = [transforms.Normalize((0.48,), (0.2,))]\n",
    "    preprocess3 = [transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]\n",
    "    \n",
    "    if alpha_mode is not None:\n",
    "        preprocess1 = [preprocess_alpha] + preprocess1\n",
    "        preprocess3 = [preprocess_alpha] + preprocess3\n",
    "    \n",
    "    if train_dist == 'cifar10':\n",
    "        opt = OPT('cifar10')\n",
    "\n",
    "        if target_dist == 'cifar10':\n",
    "            return test_loader_cifar10(opt, preprocess3, batch_size, shuffle)\n",
    "\n",
    "        elif target_dist == 'svhn':\n",
    "            return test_loader_svhn(opt, preprocess3, batch_size, shuffle)\n",
    "\n",
    "        elif target_dist == 'celeba':\n",
    "            return test_loader_celeba(opt, preprocess3, batch_size, shuffle)\n",
    "        \n",
    "        elif target_dist == 'lsun':\n",
    "            return test_loader_lsun(opt, preprocess3, batch_size, shuffle)\n",
    "        \n",
    "        elif target_dist == 'cifar100':\n",
    "            return test_loader_cifar100(opt, preprocess3, batch_size, shuffle)\n",
    "        \n",
    "        elif target_dist == 'mnist':\n",
    "            return test_loader_mnist(opt, preprocess3, batch_size, shuffle)\n",
    "        \n",
    "        elif target_dist == 'fmnist':\n",
    "            return test_loader_fmnist(opt, preprocess3, batch_size, shuffle)\n",
    "        \n",
    "        elif target_dist == 'kmnist':\n",
    "            return test_loader_kmnist(opt, preprocess3, batch_size, shuffle)\n",
    "        \n",
    "        elif target_dist == 'omniglot':\n",
    "            return test_loader_omniglot(opt, preprocess3, batch_size, shuffle)\n",
    "        \n",
    "        elif target_dist == 'notmnist':\n",
    "            return test_loader_notmnist(opt, preprocess3, batch_size, shuffle)\n",
    "        \n",
    "        elif target_dist == 'trafficsign':\n",
    "            return test_loader_trafficsign(opt, preprocess3, batch_size, shuffle)\n",
    "        \n",
    "        elif target_dist == 'noise':\n",
    "            return test_loader_noise(opt, preprocess3, batch_size, shuffle)\n",
    "        \n",
    "        elif target_dist == 'constant':\n",
    "            return test_loader_constant(opt, preprocess3, batch_size, shuffle)\n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError(\"Oops! Such match of ID & OOD doesn't exist!\")\n",
    "\n",
    "    elif train_dist == 'fmnist':\n",
    "        opt = OPT('fmnist')\n",
    "\n",
    "        if target_dist == 'fmnist':\n",
    "            return test_loader_fmnist(opt, preprocess1, batch_size, shuffle)\n",
    "            \n",
    "        elif target_dist == 'svhn':\n",
    "            return test_loader_svhn(opt, preprocess1, batch_size, shuffle)\n",
    "        \n",
    "        elif target_dist == 'celeba':\n",
    "            return test_loader_celeba(opt, preprocess1, batch_size, shuffle)\n",
    "        \n",
    "        elif target_dist == 'lsun':\n",
    "            return test_loader_lsun(opt, preprocess1, batch_size, shuffle)\n",
    "        \n",
    "        elif target_dist == 'cifar10':\n",
    "            return test_loader_cifar10(opt, preprocess1, batch_size, shuffle)\n",
    "        \n",
    "        elif target_dist == 'cifar100':\n",
    "            return test_loader_cifar100(opt, preprocess1, batch_size, shuffle)\n",
    "        \n",
    "        elif target_dist == 'mnist':\n",
    "            return test_loader_mnist(opt, preprocess1, batch_size, shuffle)\n",
    "        \n",
    "        elif target_dist == 'kmnist':\n",
    "            return test_loader_kmnist(opt, preprocess1, batch_size, shuffle)\n",
    "        \n",
    "        elif target_dist == 'omniglot':\n",
    "            return test_loader_omniglot(opt, preprocess1, batch_size, shuffle)\n",
    "            \n",
    "        elif target_dist == 'notmnist':\n",
    "            return test_loader_notmnist(opt, preprocess1, batch_size, shuffle)\n",
    "            \n",
    "        elif target_dist == 'noise':\n",
    "            return test_loader_noise(opt, preprocess1, batch_size, shuffle)\n",
    "        \n",
    "        elif target_dist == 'constant':\n",
    "            return test_loader_constant(opt, preprocess1, batch_size, shuffle)\n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError(\"Oops! Such match of ID & OOD doesn't exist!\")\n",
    "        \n",
    "    else:\n",
    "        raise NotImplementedError(\"Oops! Such match of ID & OOD doesn't exist!\")\n",
    "        \n",
    "\n",
    "def rgb_to_gray(x):\n",
    "    return torch.mean(x, dim=0, keepdim=True)\n",
    "\n",
    "\n",
    "def gray_to_rgb(x):\n",
    "    return x.repeat(3, 1, 1)\n",
    "\n",
    "\n",
    "def test_loader_cifar10(opt, preprocess, batch_size, shuffle):\n",
    "    if opt.nc == 1:\n",
    "        preprocess = [rgb_to_gray] + preprocess\n",
    "    dataset_cifar10 = dset.CIFAR10(\n",
    "        root=opt.dataroot,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize((opt.imageSize)),\n",
    "            transforms.ToTensor(),\n",
    "        ] + preprocess),\n",
    "    )\n",
    "    test_loader_cifar10 = data.DataLoader(\n",
    "        dataset_cifar10,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=int(opt.workers),\n",
    "    )\n",
    "    return test_loader_cifar10\n",
    "\n",
    "\n",
    "def test_loader_svhn(opt, preprocess, batch_size, shuffle):\n",
    "    if opt.nc == 1:\n",
    "        preprocess = [rgb_to_gray] + preprocess\n",
    "    dataset_svhn = dset.SVHN(\n",
    "        root=opt.dataroot,\n",
    "        split='test',\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize((opt.imageSize,opt.imageSize)),\n",
    "            transforms.ToTensor(),\n",
    "        ] + preprocess),\n",
    "    )\n",
    "    test_loader_svhn = data.DataLoader(\n",
    "        dataset_svhn,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=int(opt.workers),\n",
    "    )\n",
    "    return test_loader_svhn\n",
    "\n",
    "    \n",
    "def test_loader_celeba(opt, preprocess, batch_size, shuffle):\n",
    "    if opt.nc == 1:\n",
    "        preprocess = [rgb_to_gray] + preprocess\n",
    "    class CelebA(data.Dataset):\n",
    "        def __init__(self, db_path, transform=None):\n",
    "            super(CelebA, self).__init__()\n",
    "            self.db_path = db_path\n",
    "            elements = os.listdir(self.db_path)\n",
    "            self.total_path = [self.db_path + '/' + element for element in elements]\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.total_path)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            current_path = self.total_path[index]\n",
    "            img = cv2.imread(current_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(img)\n",
    "            img = self.transform(img)\n",
    "            return img\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((opt.imageSize, opt.imageSize)),\n",
    "        transforms.ToTensor(),\n",
    "    ] + preprocess)\n",
    "\n",
    "    celeba = CelebA(f'{opt.dataroot}/celeba/archive', transform=transform)\n",
    "    test_loader_celeba = data.DataLoader(\n",
    "        celeba,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    return test_loader_celeba\n",
    "\n",
    "\n",
    "def test_loader_lsun(opt, preprocess, batch_size, shuffle):\n",
    "    if opt.nc == 1:\n",
    "        preprocess = [rgb_to_gray] + preprocess\n",
    "    class LSUN(data.Dataset):\n",
    "        def __init__(self, db_path, categories=['bedroom', 'bridge', 'church_outdoor', 'classroom', 'conference_room', 'dining_room', 'kitchen', 'living_room', 'restaurant', 'tower'], transform=None):\n",
    "            super(LSUN, self).__init__()\n",
    "            self.total_path = []\n",
    "            for i in range(len(categories)):\n",
    "                self.db_path = db_path + '/' + categories[i] + '_val'\n",
    "                elements = os.listdir(self.db_path)\n",
    "                self.total_path += [self.db_path + '/' + element for element in elements if element[-4:] == '.jpg']\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.total_path)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            current_path = self.total_path[index]\n",
    "            img = cv2.imread(current_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(img)\n",
    "            img = self.transform(img)\n",
    "            return img\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(opt.imageSize), # Then the size will be H x 32 or 32 x W (32 is smaller)\n",
    "        transforms.CenterCrop(opt.imageSize),\n",
    "        transforms.ToTensor(),\n",
    "    ] + preprocess)\n",
    "\n",
    "    lsun = LSUN(f'{opt.dataroot}/LSUN_test', transform=transform)\n",
    "    test_loader_lsun = data.DataLoader(\n",
    "        lsun,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    return test_loader_lsun\n",
    "\n",
    "\n",
    "def test_loader_cifar100(opt, preprocess, batch_size, shuffle):\n",
    "    if opt.nc == 1:\n",
    "        preprocess = [rgb_to_gray] + preprocess\n",
    "    dataset_cifar100 = dset.CIFAR100(\n",
    "        root=opt.dataroot,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize((opt.imageSize)),\n",
    "            transforms.ToTensor(),\n",
    "        ] + preprocess),\n",
    "    )\n",
    "    test_loader_cifar100 = data.DataLoader(\n",
    "        dataset_cifar100,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=int(opt.workers),\n",
    "    )\n",
    "    return test_loader_cifar100\n",
    "\n",
    "\n",
    "def test_loader_mnist(opt, preprocess, batch_size, shuffle):\n",
    "    if opt.nc == 3:\n",
    "        preprocess = [gray_to_rgb] + preprocess\n",
    "    dataset_mnist = dset.MNIST(\n",
    "        root=opt.dataroot,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize((opt.imageSize, opt.imageSize)),\n",
    "            transforms.ToTensor(),\n",
    "        ] + preprocess),\n",
    "    )\n",
    "    test_loader_mnist = data.DataLoader(\n",
    "        dataset_mnist,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=int(opt.workers),\n",
    "    )\n",
    "    return test_loader_mnist\n",
    "\n",
    "    \n",
    "def test_loader_fmnist(opt, preprocess, batch_size, shuffle):\n",
    "    if opt.nc == 3:\n",
    "        preprocess = [gray_to_rgb] + preprocess\n",
    "    dataset_fmnist = dset.FashionMNIST(\n",
    "        root=opt.dataroot,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize((opt.imageSize)),\n",
    "            transforms.ToTensor(),\n",
    "        ] + preprocess),\n",
    "    )\n",
    "    test_loader_fmnist = data.DataLoader(\n",
    "        dataset_fmnist,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=int(opt.workers),\n",
    "    )\n",
    "    return test_loader_fmnist\n",
    "\n",
    "    \n",
    "def test_loader_kmnist(opt, preprocess, batch_size, shuffle):\n",
    "    if opt.nc == 3:\n",
    "        preprocess = [gray_to_rgb] + preprocess\n",
    "    dataset_kmnist = dset.KMNIST(\n",
    "        root=opt.dataroot,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize((opt.imageSize, opt.imageSize)),\n",
    "            transforms.ToTensor(),\n",
    "        ] + preprocess),\n",
    "    )\n",
    "    test_loader_kmnist = data.DataLoader(\n",
    "        dataset_kmnist,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=int(opt.workers),\n",
    "    )\n",
    "    return test_loader_kmnist\n",
    "\n",
    "    \n",
    "def test_loader_omniglot(opt, preprocess, batch_size, shuffle):\n",
    "    if opt.nc == 3:\n",
    "        preprocess = [gray_to_rgb] + preprocess\n",
    "    dataset_omniglot = dset.Omniglot(\n",
    "        root=opt.dataroot, \n",
    "        background=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize((opt.imageSize, opt.imageSize)),\n",
    "            transforms.ToTensor(),\n",
    "        ] + preprocess),\n",
    "    )\n",
    "    test_loader_omniglot = data.DataLoader(\n",
    "        dataset_omniglot,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=int(opt.workers),\n",
    "    )\n",
    "    return test_loader_omniglot\n",
    "\n",
    "    \n",
    "def test_loader_notmnist(opt, preprocess, batch_size, shuffle):\n",
    "    if opt.nc == 1:\n",
    "        preprocess = [rgb_to_gray] + preprocess\n",
    "    class notMNIST(data.Dataset):\n",
    "        def __init__(self, db_path, transform=None):\n",
    "            super(notMNIST, self).__init__()\n",
    "            self.db_path = db_path\n",
    "            self.total_path = []\n",
    "            alphabets = os.listdir(self.db_path)\n",
    "            for alphabet in alphabets:\n",
    "                path = self.db_path + '/' + alphabet\n",
    "                elements = os.listdir(path)\n",
    "                self.total_path += [path + '/' + element for element in elements]\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.total_path)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            current_path = self.total_path[index]\n",
    "            img = cv2.imread(current_path)\n",
    "            img = Image.fromarray(img)\n",
    "            img = self.transform(img)\n",
    "            return img\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((opt.imageSize, opt.imageSize)),\n",
    "        transforms.ToTensor(),\n",
    "    ] + preprocess)\n",
    "\n",
    "    notmnist = notMNIST(f'{opt.dataroot}/notMNIST_small/', transform=transform)\n",
    "    test_loader_notmnist = data.DataLoader(\n",
    "        notmnist,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    return test_loader_notmnist\n",
    "\n",
    "    \n",
    "def test_loader_trafficsign(opt, preprocess, batch_size, shuffle):\n",
    "    if opt.nc == 1:\n",
    "        preprocess = [rgb_to_gray] + preprocess\n",
    "    class trafficsign(data.Dataset):\n",
    "        def __init__(self, db_path, transform=None):\n",
    "            super(trafficsign, self).__init__()\n",
    "            self.db_path = db_path\n",
    "            elements = os.listdir(self.db_path)\n",
    "            self.total_path = [self.db_path + '/' + element for element in elements]\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.total_path)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            current_path = self.total_path[index]\n",
    "            img = cv2.imread(current_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(img)\n",
    "            img = self.transform(img)\n",
    "            return img\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((opt.imageSize, opt.imageSize)),\n",
    "        transforms.ToTensor(),\n",
    "    ] + preprocess)\n",
    "\n",
    "    ts = trafficsign(f'{opt.dataroot}/GTSRB_Final_Test_Images/Final_Test/Images', transform=transform)\n",
    "    test_loader_trafficsign = data.DataLoader(\n",
    "        ts,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    return test_loader_trafficsign\n",
    "\n",
    "    \n",
    "def test_loader_noise(opt, preprocess, batch_size, shuffle):\n",
    "    class Noise(data.Dataset):\n",
    "        def __init__(self, number=10000, transform=None):\n",
    "            super(Noise, self).__init__()\n",
    "            self.transform = transform\n",
    "            self.number = number\n",
    "            self.total_data = np.random.randint(0, 256, (self.number, opt.nc, 32, 32))\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.number\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            array = torch.tensor(self.total_data[index] / 255).float()\n",
    "            return self.transform(array)\n",
    "\n",
    "    transform = transforms.Compose(preprocess)\n",
    "\n",
    "    noise = Noise(transform=transform)\n",
    "    test_loader_noise = data.DataLoader(\n",
    "        noise,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    return test_loader_noise\n",
    "\n",
    "    \n",
    "def test_loader_constant(opt, preprocess, batch_size, shuffle):\n",
    "    class Constant(data.Dataset):\n",
    "        def __init__(self, number=10000, transform=None):\n",
    "            super(Constant, self).__init__()\n",
    "            self.number = number\n",
    "            self.total_data = torch.randint(0, 256, (self.number, opt.nc, 1, 1))\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.number\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            array = torch.tensor(self.total_data[index] / 255).float()\n",
    "            array = array.repeat(1, 32, 32)\n",
    "            return self.transform(array)\n",
    "\n",
    "    transform = transforms.Compose(preprocess)\n",
    "\n",
    "    constant = Constant(transform=transform)\n",
    "    test_loader_constant = data.DataLoader(\n",
    "        constant,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    return test_loader_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def aurocTest(train_dist, blurtype, testlist, plot=True, alpha_mode=None, alpha_value=1):\n",
    "    id_testloader = TEST_loader(train_dist, train_dist)\n",
    "    if train_dist == 'cifar10':\n",
    "        channel = 3\n",
    "    elif train_dist == 'fmnist':\n",
    "        channel = 1   \n",
    "    net = ResNet345(channel)\n",
    "    net2 = ResNet342(channel)\n",
    "    net = net.to(device)\n",
    "    net2 = net2.to(device)    \n",
    "\n",
    "    netPATH = f'saved_models/net_{train_dist}_{blurtype}.ckpt'\n",
    "    net2PATH = f'saved_models/net2_{train_dist}_{blurtype}.ckpt'\n",
    "\n",
    "    netckpt = torch.load(netPATH)\n",
    "    net2ckpt = torch.load(net2PATH)\n",
    "\n",
    "    net.load_state_dict(netckpt)\n",
    "    net2.load_state_dict(net2ckpt)\n",
    "\n",
    "    net.eval()\n",
    "    net2.eval()\n",
    "    \n",
    "    id_loss = np.zeros((100, 100))\n",
    "    for batch_idx, (inputs, targets) in enumerate(id_testloader):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = net(inputs)\n",
    "        outputs2, _ = net2(inputs)\n",
    "        id_loss[batch_idx] = torch.sum((outputs - outputs2)**2, axis=-1).detach().cpu().numpy()\n",
    "        if batch_idx == 99:\n",
    "            break\n",
    "    id_loss = id_loss.reshape(-1)  \n",
    "    \n",
    "    for oodtype in testlist:      \n",
    "        ood_testloader = TEST_loader(train_dist, oodtype, alpha_mode=alpha_mode, alpha_value=alpha_value)\n",
    "\n",
    "        ood_loss = np.zeros((100, 100))\n",
    "        n_test = 0\n",
    "        for batch_idx, inputs in enumerate(ood_testloader):\n",
    "            try:\n",
    "                inputs, _ = inputs\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            n_test += len(inputs)\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = net(inputs)\n",
    "            outputs2, _ = net2(inputs)\n",
    "            ood_loss[batch_idx] = torch.sum((outputs - outputs2)**2, axis=-1).detach().cpu().numpy()\n",
    "            if batch_idx == 99:\n",
    "                break\n",
    "        ood_loss = ood_loss.reshape(-1)    \n",
    "        print(n_test)\n",
    "        if plot:\n",
    "            plot_hist(id_loss[:n_test], ood_loss[:n_test], labels=[train_dist, oodtype])\n",
    "        auroc = AUROC(id_loss[:n_test], ood_loss[:n_test], labels=[train_dist, oodtype], plot=plot)\n",
    "        print(f'{train_dist}_{blurtype}_{oodtype} : {auroc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {'cifar10': ['svd22', 'svd28', 'dct28', 'gb', '20p', '4px'], 'fmnist': ['svd20', 'svd24', 'dct28', 'gb', '20p', '4px']}\n",
    "models = {'cifar10': ['svd22', 'svd28', 'dct28', 'gb', '20p']}\n",
    "\n",
    "testlists = {'cifar10': ['svhn', 'celeba', 'lsun', 'cifar100', 'mnist', 'fmnist', 'kmnist', \n",
    "                         'omniglot', 'notmnist', 'trafficsign', 'noise', 'constant'],\n",
    "           'fmnist': ['cifar10', 'svhn', 'celeba', 'lsun', 'cifar100', 'mnist', 'kmnist', \n",
    "                      'omniglot', 'notmnist', 'trafficsign', 'noise', 'constant']}\n",
    "# testlists = {'cifar10': ['lsun', 'celeba', 'svhn'],\n",
    "#             'fmnist': ['lsun']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_blurtype_OOD : aurocScore\n",
      "scale:  0.0\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd22_svhn : 1.000\n",
      "10000\n",
      "cifar10_svd22_celeba : 1.000\n",
      "3000\n",
      "cifar10_svd22_lsun : 1.000\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_cifar100 : 1.000\n",
      "10000\n",
      "cifar10_svd22_mnist : 1.000\n",
      "10000\n",
      "cifar10_svd22_fmnist : 1.000\n",
      "10000\n",
      "cifar10_svd22_kmnist : 1.000\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_omniglot : 1.000\n",
      "10000\n",
      "cifar10_svd22_notmnist : 1.000\n",
      "10000\n",
      "cifar10_svd22_trafficsign : 1.000\n",
      "10000\n",
      "cifar10_svd22_noise : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd22_constant : 1.000\n",
      "scale:  0.0\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd28_svhn : 1.000\n",
      "10000\n",
      "cifar10_svd28_celeba : 1.000\n",
      "3000\n",
      "cifar10_svd28_lsun : 1.000\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_cifar100 : 1.000\n",
      "10000\n",
      "cifar10_svd28_mnist : 1.000\n",
      "10000\n",
      "cifar10_svd28_fmnist : 1.000\n",
      "10000\n",
      "cifar10_svd28_kmnist : 1.000\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_omniglot : 1.000\n",
      "10000\n",
      "cifar10_svd28_notmnist : 1.000\n",
      "10000\n",
      "cifar10_svd28_trafficsign : 1.000\n",
      "10000\n",
      "cifar10_svd28_noise : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd28_constant : 1.000\n",
      "scale:  0.0\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_dct28_svhn : 1.000\n",
      "10000\n",
      "cifar10_dct28_celeba : 1.000\n",
      "3000\n",
      "cifar10_dct28_lsun : 1.000\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_cifar100 : 1.000\n",
      "10000\n",
      "cifar10_dct28_mnist : 1.000\n",
      "10000\n",
      "cifar10_dct28_fmnist : 1.000\n",
      "10000\n",
      "cifar10_dct28_kmnist : 1.000\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_omniglot : 1.000\n",
      "10000\n",
      "cifar10_dct28_notmnist : 1.000\n",
      "10000\n",
      "cifar10_dct28_trafficsign : 1.000\n",
      "10000\n",
      "cifar10_dct28_noise : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_dct28_constant : 1.000\n",
      "scale:  0.0\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_gb_svhn : 1.000\n",
      "10000\n",
      "cifar10_gb_celeba : 1.000\n",
      "3000\n",
      "cifar10_gb_lsun : 1.000\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_cifar100 : 1.000\n",
      "10000\n",
      "cifar10_gb_mnist : 1.000\n",
      "10000\n",
      "cifar10_gb_fmnist : 1.000\n",
      "10000\n",
      "cifar10_gb_kmnist : 1.000\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_omniglot : 1.000\n",
      "10000\n",
      "cifar10_gb_notmnist : 1.000\n",
      "10000\n",
      "cifar10_gb_trafficsign : 1.000\n",
      "10000\n",
      "cifar10_gb_noise : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_gb_constant : 1.000\n",
      "scale:  0.0\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_20p_svhn : 1.000\n",
      "10000\n",
      "cifar10_20p_celeba : 1.000\n",
      "3000\n",
      "cifar10_20p_lsun : 1.000\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_cifar100 : 1.000\n",
      "10000\n",
      "cifar10_20p_mnist : 1.000\n",
      "10000\n",
      "cifar10_20p_fmnist : 1.000\n",
      "10000\n",
      "cifar10_20p_kmnist : 1.000\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_omniglot : 1.000\n",
      "10000\n",
      "cifar10_20p_notmnist : 1.000\n",
      "10000\n",
      "cifar10_20p_trafficsign : 1.000\n",
      "10000\n",
      "cifar10_20p_noise : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_20p_constant : 1.000\n",
      "scale:  0.2\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd22_svhn : 0.991\n",
      "10000\n",
      "cifar10_svd22_celeba : 0.104\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.185\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_cifar100 : 0.205\n",
      "10000\n",
      "cifar10_svd22_mnist : 0.286\n",
      "10000\n",
      "cifar10_svd22_fmnist : 0.693\n",
      "10000\n",
      "cifar10_svd22_kmnist : 0.264\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_omniglot : 0.246\n",
      "10000\n",
      "cifar10_svd22_notmnist : 0.579\n",
      "10000\n",
      "cifar10_svd22_trafficsign : 0.502\n",
      "10000\n",
      "cifar10_svd22_noise : 0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd22_constant : 1.000\n",
      "scale:  0.2\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd28_svhn : 0.990\n",
      "10000\n",
      "cifar10_svd28_celeba : 0.135\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.317\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_cifar100 : 0.243\n",
      "10000\n",
      "cifar10_svd28_mnist : 0.238\n",
      "10000\n",
      "cifar10_svd28_fmnist : 0.599\n",
      "10000\n",
      "cifar10_svd28_kmnist : 0.160\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_omniglot : 0.155\n",
      "10000\n",
      "cifar10_svd28_notmnist : 0.630\n",
      "10000\n",
      "cifar10_svd28_trafficsign : 0.554\n",
      "10000\n",
      "cifar10_svd28_noise : 0.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd28_constant : 1.000\n",
      "scale:  0.2\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_dct28_svhn : 0.997\n",
      "10000\n",
      "cifar10_dct28_celeba : 0.195\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.253\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_cifar100 : 0.335\n",
      "10000\n",
      "cifar10_dct28_mnist : 0.383\n",
      "10000\n",
      "cifar10_dct28_fmnist : 0.486\n",
      "10000\n",
      "cifar10_dct28_kmnist : 0.363\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_omniglot : 0.055\n",
      "10000\n",
      "cifar10_dct28_notmnist : 0.860\n",
      "10000\n",
      "cifar10_dct28_trafficsign : 0.772\n",
      "10000\n",
      "cifar10_dct28_noise : 0.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_dct28_constant : 1.000\n",
      "scale:  0.2\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_gb_svhn : 0.980\n",
      "10000\n",
      "cifar10_gb_celeba : 0.987\n",
      "3000\n",
      "cifar10_gb_lsun : 0.984\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_cifar100 : 0.981\n",
      "10000\n",
      "cifar10_gb_mnist : 1.000\n",
      "10000\n",
      "cifar10_gb_fmnist : 0.996\n",
      "10000\n",
      "cifar10_gb_kmnist : 0.999\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_omniglot : 0.850\n",
      "10000\n",
      "cifar10_gb_notmnist : 0.975\n",
      "10000\n",
      "cifar10_gb_trafficsign : 0.991\n",
      "10000\n",
      "cifar10_gb_noise : 0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_gb_constant : 0.979\n",
      "scale:  0.2\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_20p_svhn : 0.984\n",
      "10000\n",
      "cifar10_20p_celeba : 0.988\n",
      "3000\n",
      "cifar10_20p_lsun : 0.985\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_cifar100 : 0.984\n",
      "10000\n",
      "cifar10_20p_mnist : 0.999\n",
      "10000\n",
      "cifar10_20p_fmnist : 0.995\n",
      "10000\n",
      "cifar10_20p_kmnist : 0.999\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_omniglot : 0.889\n",
      "10000\n",
      "cifar10_20p_notmnist : 0.979\n",
      "10000\n",
      "cifar10_20p_trafficsign : 0.992\n",
      "10000\n",
      "cifar10_20p_noise : 0.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_20p_constant : 0.982\n",
      "scale:  0.4\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd22_svhn : 0.987\n",
      "10000\n",
      "cifar10_svd22_celeba : 0.083\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.144\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_cifar100 : 0.181\n",
      "10000\n",
      "cifar10_svd22_mnist : 0.495\n",
      "10000\n",
      "cifar10_svd22_fmnist : 0.728\n",
      "10000\n",
      "cifar10_svd22_kmnist : 0.551\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_omniglot : 0.391\n",
      "10000\n",
      "cifar10_svd22_notmnist : 0.775\n",
      "10000\n",
      "cifar10_svd22_trafficsign : 0.357\n",
      "10000\n",
      "cifar10_svd22_noise : 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd22_constant : 1.000\n",
      "scale:  0.4\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd28_svhn : 0.975\n",
      "10000\n",
      "cifar10_svd28_celeba : 0.082\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.160\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_cifar100 : 0.169\n",
      "10000\n",
      "cifar10_svd28_mnist : 0.369\n",
      "10000\n",
      "cifar10_svd28_fmnist : 0.562\n",
      "10000\n",
      "cifar10_svd28_kmnist : 0.416\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_omniglot : 0.337\n",
      "10000\n",
      "cifar10_svd28_notmnist : 0.778\n",
      "10000\n",
      "cifar10_svd28_trafficsign : 0.374\n",
      "10000\n",
      "cifar10_svd28_noise : 0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd28_constant : 1.000\n",
      "scale:  0.4\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_dct28_svhn : 0.979\n",
      "10000\n",
      "cifar10_dct28_celeba : 0.064\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.089\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_cifar100 : 0.126\n",
      "10000\n",
      "cifar10_dct28_mnist : 0.342\n",
      "10000\n",
      "cifar10_dct28_fmnist : 0.349\n",
      "10000\n",
      "cifar10_dct28_kmnist : 0.444\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_omniglot : 0.254\n",
      "10000\n",
      "cifar10_dct28_notmnist : 0.866\n",
      "10000\n",
      "cifar10_dct28_trafficsign : 0.479\n",
      "10000\n",
      "cifar10_dct28_noise : 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_dct28_constant : 1.000\n",
      "scale:  0.4\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_gb_svhn : 0.742\n",
      "10000\n",
      "cifar10_gb_celeba : 0.817\n",
      "3000\n",
      "cifar10_gb_lsun : 0.758\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_cifar100 : 0.765\n",
      "10000\n",
      "cifar10_gb_mnist : 0.998\n",
      "10000\n",
      "cifar10_gb_fmnist : 0.954\n",
      "10000\n",
      "cifar10_gb_kmnist : 0.995\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_omniglot : 0.046\n",
      "10000\n",
      "cifar10_gb_notmnist : 0.798\n",
      "10000\n",
      "cifar10_gb_trafficsign : 0.888\n",
      "10000\n",
      "cifar10_gb_noise : 0.871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_gb_constant : 0.763\n",
      "scale:  0.4\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_20p_svhn : 0.788\n",
      "10000\n",
      "cifar10_20p_celeba : 0.839\n",
      "3000\n",
      "cifar10_20p_lsun : 0.782\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_cifar100 : 0.791\n",
      "10000\n",
      "cifar10_20p_mnist : 0.997\n",
      "10000\n",
      "cifar10_20p_fmnist : 0.947\n",
      "10000\n",
      "cifar10_20p_kmnist : 0.995\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_omniglot : 0.090\n",
      "10000\n",
      "cifar10_20p_notmnist : 0.812\n",
      "10000\n",
      "cifar10_20p_trafficsign : 0.902\n",
      "10000\n",
      "cifar10_20p_noise : 0.900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_20p_constant : 0.784\n",
      "scale:  0.6000000000000001\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd22_svhn : 0.983\n",
      "10000\n",
      "cifar10_svd22_celeba : 0.207\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.237\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_cifar100 : 0.262\n",
      "10000\n",
      "cifar10_svd22_mnist : 0.732\n",
      "10000\n",
      "cifar10_svd22_fmnist : 0.835\n",
      "10000\n",
      "cifar10_svd22_kmnist : 0.809\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_omniglot : 0.571\n",
      "10000\n",
      "cifar10_svd22_notmnist : 0.874\n",
      "10000\n",
      "cifar10_svd22_trafficsign : 0.347\n",
      "10000\n",
      "cifar10_svd22_noise : 0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd22_constant : 0.999\n",
      "scale:  0.6000000000000001\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd28_svhn : 0.969\n",
      "10000\n",
      "cifar10_svd28_celeba : 0.194\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.236\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_cifar100 : 0.247\n",
      "10000\n",
      "cifar10_svd28_mnist : 0.643\n",
      "10000\n",
      "cifar10_svd28_fmnist : 0.690\n",
      "10000\n",
      "cifar10_svd28_kmnist : 0.732\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_omniglot : 0.506\n",
      "10000\n",
      "cifar10_svd28_notmnist : 0.867\n",
      "10000\n",
      "cifar10_svd28_trafficsign : 0.332\n",
      "10000\n",
      "cifar10_svd28_noise : 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd28_constant : 1.000\n",
      "scale:  0.6000000000000001\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_dct28_svhn : 0.945\n",
      "10000\n",
      "cifar10_dct28_celeba : 0.182\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.202\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_cifar100 : 0.218\n",
      "10000\n",
      "cifar10_dct28_mnist : 0.591\n",
      "10000\n",
      "cifar10_dct28_fmnist : 0.572\n",
      "10000\n",
      "cifar10_dct28_kmnist : 0.738\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_omniglot : 0.480\n",
      "10000\n",
      "cifar10_dct28_notmnist : 0.859\n",
      "10000\n",
      "cifar10_dct28_trafficsign : 0.399\n",
      "10000\n",
      "cifar10_dct28_noise : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_dct28_constant : 1.000\n",
      "scale:  0.6000000000000001\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_gb_svhn : 0.435\n",
      "10000\n",
      "cifar10_gb_celeba : 0.588\n",
      "3000\n",
      "cifar10_gb_lsun : 0.423\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_cifar100 : 0.486\n",
      "10000\n",
      "cifar10_gb_mnist : 0.997\n",
      "10000\n",
      "cifar10_gb_fmnist : 0.884\n",
      "10000\n",
      "cifar10_gb_kmnist : 0.992\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_omniglot : 0.087\n",
      "10000\n",
      "cifar10_gb_notmnist : 0.793\n",
      "10000\n",
      "cifar10_gb_trafficsign : 0.760\n",
      "10000\n",
      "cifar10_gb_noise : 0.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_gb_constant : 0.558\n",
      "scale:  0.6000000000000001\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_20p_svhn : 0.488\n",
      "10000\n",
      "cifar10_20p_celeba : 0.589\n",
      "3000\n",
      "cifar10_20p_lsun : 0.439\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_cifar100 : 0.505\n",
      "10000\n",
      "cifar10_20p_mnist : 0.995\n",
      "10000\n",
      "cifar10_20p_fmnist : 0.857\n",
      "10000\n",
      "cifar10_20p_kmnist : 0.990\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_omniglot : 0.129\n",
      "10000\n",
      "cifar10_20p_notmnist : 0.794\n",
      "10000\n",
      "cifar10_20p_trafficsign : 0.779\n",
      "10000\n",
      "cifar10_20p_noise : 0.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_20p_constant : 0.571\n",
      "scale:  0.8\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd22_svhn : 0.985\n",
      "10000\n",
      "cifar10_svd22_celeba : 0.346\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.360\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_cifar100 : 0.375\n",
      "10000\n",
      "cifar10_svd22_mnist : 0.868\n",
      "10000\n",
      "cifar10_svd22_fmnist : 0.889\n",
      "10000\n",
      "cifar10_svd22_kmnist : 0.922\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_omniglot : 0.835\n",
      "10000\n",
      "cifar10_svd22_notmnist : 0.938\n",
      "10000\n",
      "cifar10_svd22_trafficsign : 0.406\n",
      "10000\n",
      "cifar10_svd22_noise : 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd22_constant : 0.999\n",
      "scale:  0.8\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd28_svhn : 0.971\n",
      "10000\n",
      "cifar10_svd28_celeba : 0.341\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.358\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_cifar100 : 0.367\n",
      "10000\n",
      "cifar10_svd28_mnist : 0.826\n",
      "10000\n",
      "cifar10_svd28_fmnist : 0.768\n",
      "10000\n",
      "cifar10_svd28_kmnist : 0.893\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_omniglot : 0.776\n",
      "10000\n",
      "cifar10_svd28_notmnist : 0.937\n",
      "10000\n",
      "cifar10_svd28_trafficsign : 0.373\n",
      "10000\n",
      "cifar10_svd28_noise : 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd28_constant : 1.000\n",
      "scale:  0.8\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_dct28_svhn : 0.904\n",
      "10000\n",
      "cifar10_dct28_celeba : 0.337\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.348\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_cifar100 : 0.351\n",
      "10000\n",
      "cifar10_dct28_mnist : 0.806\n",
      "10000\n",
      "cifar10_dct28_fmnist : 0.699\n",
      "10000\n",
      "cifar10_dct28_kmnist : 0.897\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_omniglot : 0.764\n",
      "10000\n",
      "cifar10_dct28_notmnist : 0.925\n",
      "10000\n",
      "cifar10_dct28_trafficsign : 0.416\n",
      "10000\n",
      "cifar10_dct28_noise : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_dct28_constant : 1.000\n",
      "scale:  0.8\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_gb_svhn : 0.302\n",
      "10000\n",
      "cifar10_gb_celeba : 0.566\n",
      "3000\n",
      "cifar10_gb_lsun : 0.353\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_cifar100 : 0.434\n",
      "10000\n",
      "cifar10_gb_mnist : 0.999\n",
      "10000\n",
      "cifar10_gb_fmnist : 0.918\n",
      "10000\n",
      "cifar10_gb_kmnist : 0.996\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_omniglot : 0.858\n",
      "10000\n",
      "cifar10_gb_notmnist : 0.962\n",
      "10000\n",
      "cifar10_gb_trafficsign : 0.719\n",
      "10000\n",
      "cifar10_gb_noise : 0.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_gb_constant : 0.567\n",
      "scale:  0.8\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_20p_svhn : 0.348\n",
      "10000\n",
      "cifar10_20p_celeba : 0.543\n",
      "3000\n",
      "cifar10_20p_lsun : 0.350\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_cifar100 : 0.439\n",
      "10000\n",
      "cifar10_20p_mnist : 0.997\n",
      "10000\n",
      "cifar10_20p_fmnist : 0.883\n",
      "10000\n",
      "cifar10_20p_kmnist : 0.993\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_omniglot : 0.873\n",
      "10000\n",
      "cifar10_20p_notmnist : 0.957\n",
      "10000\n",
      "cifar10_20p_trafficsign : 0.731\n",
      "10000\n",
      "cifar10_20p_noise : 0.691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_20p_constant : 0.557\n",
      "scale:  1.0\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd22_svhn : 0.987\n",
      "10000\n",
      "cifar10_svd22_celeba : 0.577\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.577\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_cifar100 : 0.561\n",
      "10000\n",
      "cifar10_svd22_mnist : 0.963\n",
      "10000\n",
      "cifar10_svd22_fmnist : 0.951\n",
      "10000\n",
      "cifar10_svd22_kmnist : 0.977\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_omniglot : 0.966\n",
      "10000\n",
      "cifar10_svd22_notmnist : 0.985\n",
      "10000\n",
      "cifar10_svd22_trafficsign : 0.502\n",
      "10000\n",
      "cifar10_svd22_noise : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd22_constant : 0.999\n",
      "scale:  1.0\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd28_svhn : 0.977\n",
      "10000\n",
      "cifar10_svd28_celeba : 0.578\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.574\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_cifar100 : 0.558\n",
      "10000\n",
      "cifar10_svd28_mnist : 0.946\n",
      "10000\n",
      "cifar10_svd28_fmnist : 0.873\n",
      "10000\n",
      "cifar10_svd28_kmnist : 0.969\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_omniglot : 0.940\n",
      "10000\n",
      "cifar10_svd28_notmnist : 0.985\n",
      "10000\n",
      "cifar10_svd28_trafficsign : 0.461\n",
      "10000\n",
      "cifar10_svd28_noise : 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd28_constant : 1.000\n",
      "scale:  1.0\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_dct28_svhn : 0.875\n",
      "10000\n",
      "cifar10_dct28_celeba : 0.578\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.573\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_cifar100 : 0.549\n",
      "10000\n",
      "cifar10_dct28_mnist : 0.944\n",
      "10000\n",
      "cifar10_dct28_fmnist : 0.842\n",
      "10000\n",
      "cifar10_dct28_kmnist : 0.972\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_omniglot : 0.941\n",
      "10000\n",
      "cifar10_dct28_notmnist : 0.983\n",
      "10000\n",
      "cifar10_dct28_trafficsign : 0.492\n",
      "10000\n",
      "cifar10_dct28_noise : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_dct28_constant : 1.000\n",
      "scale:  1.0\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_gb_svhn : 0.330\n",
      "10000\n",
      "cifar10_gb_celeba : 0.703\n",
      "3000\n",
      "cifar10_gb_lsun : 0.523\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_cifar100 : 0.559\n",
      "10000\n",
      "cifar10_gb_mnist : 1.000\n",
      "10000\n",
      "cifar10_gb_fmnist : 0.959\n",
      "10000\n",
      "cifar10_gb_kmnist : 0.999\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_omniglot : 1.000\n",
      "10000\n",
      "cifar10_gb_notmnist : 0.998\n",
      "10000\n",
      "cifar10_gb_trafficsign : 0.727\n",
      "10000\n",
      "cifar10_gb_noise : 0.868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_gb_constant : 0.734\n",
      "scale:  1.0\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_20p_svhn : 0.372\n",
      "10000\n",
      "cifar10_20p_celeba : 0.654\n",
      "3000\n",
      "cifar10_20p_lsun : 0.495\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_cifar100 : 0.546\n",
      "10000\n",
      "cifar10_20p_mnist : 0.999\n",
      "10000\n",
      "cifar10_20p_fmnist : 0.935\n",
      "10000\n",
      "cifar10_20p_kmnist : 0.997\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_omniglot : 1.000\n",
      "10000\n",
      "cifar10_20p_notmnist : 0.997\n",
      "10000\n",
      "cifar10_20p_trafficsign : 0.730\n",
      "10000\n",
      "cifar10_20p_noise : 0.858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_20p_constant : 0.698\n",
      "scale:  1.2000000000000002\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd22_svhn : 0.970\n",
      "10000\n",
      "cifar10_svd22_celeba : 0.768\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.757\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_cifar100 : 0.715\n",
      "10000\n",
      "cifar10_svd22_mnist : 0.977\n",
      "10000\n",
      "cifar10_svd22_fmnist : 0.976\n",
      "10000\n",
      "cifar10_svd22_kmnist : 0.987\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_omniglot : 0.974\n",
      "10000\n",
      "cifar10_svd22_notmnist : 0.989\n",
      "10000\n",
      "cifar10_svd22_trafficsign : 0.564\n",
      "10000\n",
      "cifar10_svd22_noise : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd22_constant : 1.000\n",
      "scale:  1.2000000000000002\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd28_svhn : 0.972\n",
      "10000\n",
      "cifar10_svd28_celeba : 0.771\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.753\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_cifar100 : 0.711\n",
      "10000\n",
      "cifar10_svd28_mnist : 0.971\n",
      "10000\n",
      "cifar10_svd28_fmnist : 0.938\n",
      "10000\n",
      "cifar10_svd28_kmnist : 0.987\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_omniglot : 0.959\n",
      "10000\n",
      "cifar10_svd28_notmnist : 0.990\n",
      "10000\n",
      "cifar10_svd28_trafficsign : 0.522\n",
      "10000\n",
      "cifar10_svd28_noise : 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd28_constant : 1.000\n",
      "scale:  1.2000000000000002\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_dct28_svhn : 0.860\n",
      "10000\n",
      "cifar10_dct28_celeba : 0.770\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.756\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_cifar100 : 0.708\n",
      "10000\n",
      "cifar10_dct28_mnist : 0.974\n",
      "10000\n",
      "cifar10_dct28_fmnist : 0.927\n",
      "10000\n",
      "cifar10_dct28_kmnist : 0.989\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_omniglot : 0.960\n",
      "10000\n",
      "cifar10_dct28_notmnist : 0.989\n",
      "10000\n",
      "cifar10_dct28_trafficsign : 0.537\n",
      "10000\n",
      "cifar10_dct28_noise : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_dct28_constant : 1.000\n",
      "scale:  1.2000000000000002\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_gb_svhn : 0.444\n",
      "10000\n",
      "cifar10_gb_celeba : 0.825\n",
      "3000\n",
      "cifar10_gb_lsun : 0.733\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_cifar100 : 0.705\n",
      "10000\n",
      "cifar10_gb_mnist : 1.000\n",
      "10000\n",
      "cifar10_gb_fmnist : 0.978\n",
      "10000\n",
      "cifar10_gb_kmnist : 1.000\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_omniglot : 1.000\n",
      "10000\n",
      "cifar10_gb_notmnist : 0.999\n",
      "10000\n",
      "cifar10_gb_trafficsign : 0.720\n",
      "10000\n",
      "cifar10_gb_noise : 0.964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_gb_constant : 0.842\n",
      "scale:  1.2000000000000002\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_20p_svhn : 0.480\n",
      "10000\n",
      "cifar10_20p_celeba : 0.767\n",
      "3000\n",
      "cifar10_20p_lsun : 0.689\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_cifar100 : 0.676\n",
      "10000\n",
      "cifar10_20p_mnist : 1.000\n",
      "10000\n",
      "cifar10_20p_fmnist : 0.963\n",
      "10000\n",
      "cifar10_20p_kmnist : 0.999\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_omniglot : 1.000\n",
      "10000\n",
      "cifar10_20p_notmnist : 0.998\n",
      "10000\n",
      "cifar10_20p_trafficsign : 0.716\n",
      "10000\n",
      "cifar10_20p_noise : 0.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_20p_constant : 0.805\n",
      "scale:  1.4000000000000001\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd22_svhn : 0.950\n",
      "10000\n",
      "cifar10_svd22_celeba : 0.856\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.836\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_cifar100 : 0.800\n",
      "10000\n",
      "cifar10_svd22_mnist : 0.981\n",
      "10000\n",
      "cifar10_svd22_fmnist : 0.984\n",
      "10000\n",
      "cifar10_svd22_kmnist : 0.991\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_omniglot : 0.977\n",
      "10000\n",
      "cifar10_svd22_notmnist : 0.991\n",
      "10000\n",
      "cifar10_svd22_trafficsign : 0.613\n",
      "10000\n",
      "cifar10_svd22_noise : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd22_constant : 1.000\n",
      "scale:  1.4000000000000001\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd28_svhn : 0.962\n",
      "10000\n",
      "cifar10_svd28_celeba : 0.858\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.830\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_cifar100 : 0.794\n",
      "10000\n",
      "cifar10_svd28_mnist : 0.979\n",
      "10000\n",
      "cifar10_svd28_fmnist : 0.964\n",
      "10000\n",
      "cifar10_svd28_kmnist : 0.993\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_omniglot : 0.963\n",
      "10000\n",
      "cifar10_svd28_notmnist : 0.992\n",
      "10000\n",
      "cifar10_svd28_trafficsign : 0.569\n",
      "10000\n",
      "cifar10_svd28_noise : 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd28_constant : 1.000\n",
      "scale:  1.4000000000000001\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_dct28_svhn : 0.861\n",
      "10000\n",
      "cifar10_dct28_celeba : 0.858\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.837\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_cifar100 : 0.796\n",
      "10000\n",
      "cifar10_dct28_mnist : 0.983\n",
      "10000\n",
      "cifar10_dct28_fmnist : 0.961\n",
      "10000\n",
      "cifar10_dct28_kmnist : 0.994\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_omniglot : 0.964\n",
      "10000\n",
      "cifar10_dct28_notmnist : 0.991\n",
      "10000\n",
      "cifar10_dct28_trafficsign : 0.574\n",
      "10000\n",
      "cifar10_dct28_noise : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_dct28_constant : 1.000\n",
      "scale:  1.4000000000000001\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_gb_svhn : 0.580\n",
      "10000\n",
      "cifar10_gb_celeba : 0.890\n",
      "3000\n",
      "cifar10_gb_lsun : 0.857\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_cifar100 : 0.818\n",
      "10000\n",
      "cifar10_gb_mnist : 1.000\n",
      "10000\n",
      "cifar10_gb_fmnist : 0.987\n",
      "10000\n",
      "cifar10_gb_kmnist : 1.000\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_omniglot : 1.000\n",
      "10000\n",
      "cifar10_gb_notmnist : 0.999\n",
      "10000\n",
      "cifar10_gb_trafficsign : 0.717\n",
      "10000\n",
      "cifar10_gb_noise : 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_gb_constant : 0.895\n",
      "scale:  1.4000000000000001\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_20p_svhn : 0.602\n",
      "10000\n",
      "cifar10_20p_celeba : 0.836\n",
      "3000\n",
      "cifar10_20p_lsun : 0.816\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_cifar100 : 0.783\n",
      "10000\n",
      "cifar10_20p_mnist : 1.000\n",
      "10000\n",
      "cifar10_20p_fmnist : 0.976\n",
      "10000\n",
      "cifar10_20p_kmnist : 0.999\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_omniglot : 1.000\n",
      "10000\n",
      "cifar10_20p_notmnist : 0.999\n",
      "10000\n",
      "cifar10_20p_trafficsign : 0.708\n",
      "10000\n",
      "cifar10_20p_noise : 0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_20p_constant : 0.859\n",
      "scale:  1.6\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd22_svhn : 0.926\n",
      "10000\n",
      "cifar10_svd22_celeba : 0.894\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.865\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_cifar100 : 0.842\n",
      "10000\n",
      "cifar10_svd22_mnist : 0.984\n",
      "10000\n",
      "cifar10_svd22_fmnist : 0.987\n",
      "10000\n",
      "cifar10_svd22_kmnist : 0.992\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_omniglot : 0.978\n",
      "10000\n",
      "cifar10_svd22_notmnist : 0.992\n",
      "10000\n",
      "cifar10_svd22_trafficsign : 0.650\n",
      "10000\n",
      "cifar10_svd22_noise : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd22_constant : 1.000\n",
      "scale:  1.6\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd28_svhn : 0.950\n",
      "10000\n",
      "cifar10_svd28_celeba : 0.895\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.859\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_cifar100 : 0.833\n",
      "10000\n",
      "cifar10_svd28_mnist : 0.982\n",
      "10000\n",
      "cifar10_svd28_fmnist : 0.975\n",
      "10000\n",
      "cifar10_svd28_kmnist : 0.995\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_omniglot : 0.963\n",
      "10000\n",
      "cifar10_svd28_notmnist : 0.993\n",
      "10000\n",
      "cifar10_svd28_trafficsign : 0.607\n",
      "10000\n",
      "cifar10_svd28_noise : 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd28_constant : 1.000\n",
      "scale:  1.6\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_dct28_svhn : 0.867\n",
      "10000\n",
      "cifar10_dct28_celeba : 0.895\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.865\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_cifar100 : 0.837\n",
      "10000\n",
      "cifar10_dct28_mnist : 0.987\n",
      "10000\n",
      "cifar10_dct28_fmnist : 0.975\n",
      "10000\n",
      "cifar10_dct28_kmnist : 0.996\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_omniglot : 0.965\n",
      "10000\n",
      "cifar10_dct28_notmnist : 0.992\n",
      "10000\n",
      "cifar10_dct28_trafficsign : 0.610\n",
      "10000\n",
      "cifar10_dct28_noise : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_dct28_constant : 1.000\n",
      "scale:  1.6\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_gb_svhn : 0.689\n",
      "10000\n",
      "cifar10_gb_celeba : 0.926\n",
      "3000\n",
      "cifar10_gb_lsun : 0.920\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_cifar100 : 0.890\n",
      "10000\n",
      "cifar10_gb_mnist : 1.000\n",
      "10000\n",
      "cifar10_gb_fmnist : 0.991\n",
      "10000\n",
      "cifar10_gb_kmnist : 1.000\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_omniglot : 1.000\n",
      "10000\n",
      "cifar10_gb_notmnist : 0.999\n",
      "10000\n",
      "cifar10_gb_trafficsign : 0.719\n",
      "10000\n",
      "cifar10_gb_noise : 0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_gb_constant : 0.926\n",
      "scale:  1.6\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_20p_svhn : 0.698\n",
      "10000\n",
      "cifar10_20p_celeba : 0.880\n",
      "3000\n",
      "cifar10_20p_lsun : 0.887\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_cifar100 : 0.858\n",
      "10000\n",
      "cifar10_20p_mnist : 1.000\n",
      "10000\n",
      "cifar10_20p_fmnist : 0.983\n",
      "10000\n",
      "cifar10_20p_kmnist : 0.999\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_omniglot : 1.000\n",
      "10000\n",
      "cifar10_20p_notmnist : 0.999\n",
      "10000\n",
      "cifar10_20p_trafficsign : 0.708\n",
      "10000\n",
      "cifar10_20p_noise : 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_20p_constant : 0.901\n",
      "scale:  1.8\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd22_svhn : 0.893\n",
      "10000\n",
      "cifar10_svd22_celeba : 0.910\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.872\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_cifar100 : 0.858\n",
      "10000\n",
      "cifar10_svd22_mnist : 0.986\n",
      "10000\n",
      "cifar10_svd22_fmnist : 0.989\n",
      "10000\n",
      "cifar10_svd22_kmnist : 0.993\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_omniglot : 0.980\n",
      "10000\n",
      "cifar10_svd22_notmnist : 0.992\n",
      "10000\n",
      "cifar10_svd22_trafficsign : 0.676\n",
      "10000\n",
      "cifar10_svd22_noise : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd22_constant : 1.000\n",
      "scale:  1.8\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_svd28_svhn : 0.934\n",
      "10000\n",
      "cifar10_svd28_celeba : 0.910\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.865\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_cifar100 : 0.848\n",
      "10000\n",
      "cifar10_svd28_mnist : 0.985\n",
      "10000\n",
      "cifar10_svd28_fmnist : 0.981\n",
      "10000\n",
      "cifar10_svd28_kmnist : 0.996\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_omniglot : 0.962\n",
      "10000\n",
      "cifar10_svd28_notmnist : 0.994\n",
      "10000\n",
      "cifar10_svd28_trafficsign : 0.639\n",
      "10000\n",
      "cifar10_svd28_noise : 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd28_constant : 1.000\n",
      "scale:  1.8\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_dct28_svhn : 0.872\n",
      "10000\n",
      "cifar10_dct28_celeba : 0.911\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.871\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_cifar100 : 0.852\n",
      "10000\n",
      "cifar10_dct28_mnist : 0.989\n",
      "10000\n",
      "cifar10_dct28_fmnist : 0.982\n",
      "10000\n",
      "cifar10_dct28_kmnist : 0.997\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_omniglot : 0.964\n",
      "10000\n",
      "cifar10_dct28_notmnist : 0.993\n",
      "10000\n",
      "cifar10_dct28_trafficsign : 0.640\n",
      "10000\n",
      "cifar10_dct28_noise : 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_dct28_constant : 1.000\n",
      "scale:  1.8\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_gb_svhn : 0.767\n",
      "10000\n",
      "cifar10_gb_celeba : 0.946\n",
      "3000\n",
      "cifar10_gb_lsun : 0.952\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_cifar100 : 0.931\n",
      "10000\n",
      "cifar10_gb_mnist : 1.000\n",
      "10000\n",
      "cifar10_gb_fmnist : 0.994\n",
      "10000\n",
      "cifar10_gb_kmnist : 1.000\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_omniglot : 1.000\n",
      "10000\n",
      "cifar10_gb_notmnist : 1.000\n",
      "10000\n",
      "cifar10_gb_trafficsign : 0.724\n",
      "10000\n",
      "cifar10_gb_noise : 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_gb_constant : 0.947\n",
      "scale:  1.8\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ../data/test_32x32.mat\n",
      "10000\n",
      "cifar10_20p_svhn : 0.766\n",
      "10000\n",
      "cifar10_20p_celeba : 0.909\n",
      "3000\n",
      "cifar10_20p_lsun : 0.927\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_cifar100 : 0.905\n",
      "10000\n",
      "cifar10_20p_mnist : 1.000\n",
      "10000\n",
      "cifar10_20p_fmnist : 0.987\n",
      "10000\n",
      "cifar10_20p_kmnist : 0.999\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_omniglot : 1.000\n",
      "10000\n",
      "cifar10_20p_notmnist : 0.999\n",
      "10000\n",
      "cifar10_20p_trafficsign : 0.712\n",
      "10000\n",
      "cifar10_20p_noise : 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:515: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_20p_constant : 0.924\n"
     ]
    }
   ],
   "source": [
    "print('ID_blurtype_OOD : aurocScore')\n",
    "for k in models:\n",
    "    for i in range(10):\n",
    "        for b in models[k]:\n",
    "            print('scale: ', 0.2*i)\n",
    "            aurocTest(k, b, testlists[k], plot=False, alpha_mode='zero', alpha_value=0.2*i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([100, 3, 32, 32])\n",
      "tensor([[[0.5368, 0.5368, 0.5368,  ..., 0.5368, 0.5368, 0.5368],\n",
      "         [0.5368, 0.5368, 0.5368,  ..., 0.5368, 0.5368, 0.5368],\n",
      "         [0.5368, 0.5368, 0.5368,  ..., 0.5368, 0.5368, 0.5368],\n",
      "         ...,\n",
      "         [0.5368, 0.5368, 0.5368,  ..., 0.5368, 0.5368, 0.5368],\n",
      "         [0.5368, 0.5368, 0.5368,  ..., 0.5368, 0.5368, 0.5368],\n",
      "         [0.5368, 0.5368, 0.5368,  ..., 0.5368, 0.5368, 0.5368]],\n",
      "\n",
      "        [[0.5908, 0.5908, 0.5908,  ..., 0.5908, 0.5908, 0.5908],\n",
      "         [0.5908, 0.5908, 0.5908,  ..., 0.5908, 0.5908, 0.5908],\n",
      "         [0.5908, 0.5908, 0.5908,  ..., 0.5908, 0.5908, 0.5908],\n",
      "         ...,\n",
      "         [0.5908, 0.5908, 0.5908,  ..., 0.5908, 0.5908, 0.5908],\n",
      "         [0.5908, 0.5908, 0.5908,  ..., 0.5908, 0.5908, 0.5908],\n",
      "         [0.5908, 0.5908, 0.5908,  ..., 0.5908, 0.5908, 0.5908]],\n",
      "\n",
      "        [[0.7637, 0.7637, 0.7637,  ..., 0.7637, 0.7637, 0.7637],\n",
      "         [0.7637, 0.7637, 0.7637,  ..., 0.7637, 0.7637, 0.7637],\n",
      "         [0.7637, 0.7637, 0.7637,  ..., 0.7637, 0.7637, 0.7637],\n",
      "         ...,\n",
      "         [0.7637, 0.7637, 0.7637,  ..., 0.7637, 0.7637, 0.7637],\n",
      "         [0.7637, 0.7637, 0.7637,  ..., 0.7637, 0.7637, 0.7637],\n",
      "         [0.7637, 0.7637, 0.7637,  ..., 0.7637, 0.7637, 0.7637]]])\n",
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "cannot do a non-empty take from an empty axes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-030e997da99f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maurocTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cifar10'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'lsun'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-23a7034568ff>\u001b[0m in \u001b[0;36maurocTest\u001b[0;34m(train_dist, blurtype, testlist, plot, alpha)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mplot_hist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mood_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moodtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mauroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAUROC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mood_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moodtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{train_dist}_{blurtype}_{oodtype} : {auroc:.3f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-422e3c977c2b>\u001b[0m in \u001b[0;36mAUROC\u001b[0;34m(labels, plot, *args)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mlabel_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dist_Grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;31m#plot_roc_curve(fpr, tpr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mrocauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    912\u001b[0m     \"\"\"\n\u001b[1;32m    913\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 914\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0;31m# accumulate the true positives with decreasing threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     \u001b[0mtps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstable_cumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthreshold_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;31m# express fps as a cumsum to ensure fps is increasing even in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mstable_cumsum\u001b[0;34m(arr, axis, rtol, atol)\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m     if not np.all(np.isclose(out.take(-1, axis=axis), expected, rtol=rtol,\n\u001b[0m\u001b[1;32m    910\u001b[0m                              atol=atol, equal_nan=True)):\n\u001b[1;32m    911\u001b[0m         warnings.warn('cumsum was found to be unstable: '\n",
      "\u001b[0;31mIndexError\u001b[0m: cannot do a non-empty take from an empty axes."
     ]
    }
   ],
   "source": [
    "aurocTest('cifar10', 'gb', ['lsun'], plot=False, alpha_mode=None, alpha_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([100, 3, 32, 32])\n",
      "tensor([[[ 1.7775,  1.7775,  1.7775,  ...,  1.7775,  1.7775,  1.7775],\n",
      "         [ 1.7775,  1.7775,  1.7775,  ...,  1.7775,  1.7775,  1.7775],\n",
      "         [ 1.7775,  1.7775,  1.7775,  ...,  1.7775,  1.7775,  1.7775],\n",
      "         ...,\n",
      "         [ 1.7775,  1.7775,  1.7775,  ...,  1.7775,  1.7775,  1.7775],\n",
      "         [ 1.7775,  1.7775,  1.7775,  ...,  1.7775,  1.7775,  1.7775],\n",
      "         [ 1.7775,  1.7775,  1.7775,  ...,  1.7775,  1.7775,  1.7775]],\n",
      "\n",
      "        [[-0.8842, -0.8842, -0.8842,  ..., -0.8842, -0.8842, -0.8842],\n",
      "         [-0.8842, -0.8842, -0.8842,  ..., -0.8842, -0.8842, -0.8842],\n",
      "         [-0.8842, -0.8842, -0.8842,  ..., -0.8842, -0.8842, -0.8842],\n",
      "         ...,\n",
      "         [-0.8842, -0.8842, -0.8842,  ..., -0.8842, -0.8842, -0.8842],\n",
      "         [-0.8842, -0.8842, -0.8842,  ..., -0.8842, -0.8842, -0.8842],\n",
      "         [-0.8842, -0.8842, -0.8842,  ..., -0.8842, -0.8842, -0.8842]],\n",
      "\n",
      "        [[-1.4410, -1.4410, -1.4410,  ..., -1.4410, -1.4410, -1.4410],\n",
      "         [-1.4410, -1.4410, -1.4410,  ..., -1.4410, -1.4410, -1.4410],\n",
      "         [-1.4410, -1.4410, -1.4410,  ..., -1.4410, -1.4410, -1.4410],\n",
      "         ...,\n",
      "         [-1.4410, -1.4410, -1.4410,  ..., -1.4410, -1.4410, -1.4410],\n",
      "         [-1.4410, -1.4410, -1.4410,  ..., -1.4410, -1.4410, -1.4410],\n",
      "         [-1.4410, -1.4410, -1.4410,  ..., -1.4410, -1.4410, -1.4410]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:502: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "cannot do a non-empty take from an empty axes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-abfa75c47729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maurocTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cifar10'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'svd22'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-23a7034568ff>\u001b[0m in \u001b[0;36maurocTest\u001b[0;34m(train_dist, blurtype, testlist, plot, alpha)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mplot_hist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mood_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moodtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mauroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAUROC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mood_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moodtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{train_dist}_{blurtype}_{oodtype} : {auroc:.3f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-422e3c977c2b>\u001b[0m in \u001b[0;36mAUROC\u001b[0;34m(labels, plot, *args)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mlabel_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dist_Grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;31m#plot_roc_curve(fpr, tpr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mrocauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    912\u001b[0m     \"\"\"\n\u001b[1;32m    913\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 914\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0;31m# accumulate the true positives with decreasing threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     \u001b[0mtps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstable_cumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthreshold_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;31m# express fps as a cumsum to ensure fps is increasing even in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mstable_cumsum\u001b[0;34m(arr, axis, rtol, atol)\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m     if not np.all(np.isclose(out.take(-1, axis=axis), expected, rtol=rtol,\n\u001b[0m\u001b[1;32m    910\u001b[0m                              atol=atol, equal_nan=True)):\n\u001b[1;32m    911\u001b[0m         warnings.warn('cumsum was found to be unstable: '\n",
      "\u001b[0;31mIndexError\u001b[0m: cannot do a non-empty take from an empty axes."
     ]
    }
   ],
   "source": [
    "aurocTest('cifar10', 'svd22', ['constant'], plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_blurtype_OOD : aurocScore\n",
      "scale:  0.0\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.997\n",
      "scale:  0.1\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.109\n",
      "scale:  0.2\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.035\n",
      "scale:  0.30000000000000004\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.021\n",
      "scale:  0.4\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.027\n",
      "scale:  0.5\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.049\n",
      "scale:  0.6000000000000001\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.097\n",
      "scale:  0.7000000000000001\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.183\n",
      "scale:  0.8\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.303\n",
      "scale:  0.9\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.442\n",
      "scale:  0.0\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd28_lsun : 1.000\n",
      "scale:  0.1\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.186\n",
      "scale:  0.2\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.043\n",
      "scale:  0.30000000000000004\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.026\n",
      "scale:  0.4\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.028\n",
      "scale:  0.5\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.048\n",
      "scale:  0.6000000000000001\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.096\n",
      "scale:  0.7000000000000001\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.180\n",
      "scale:  0.8\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.300\n",
      "scale:  0.9\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.438\n",
      "scale:  0.0\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_dct28_lsun : 1.000\n",
      "scale:  0.1\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.408\n",
      "scale:  0.2\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.041\n",
      "scale:  0.30000000000000004\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.010\n",
      "scale:  0.4\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.014\n",
      "scale:  0.5\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.034\n",
      "scale:  0.6000000000000001\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.083\n",
      "scale:  0.7000000000000001\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.169\n",
      "scale:  0.8\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.291\n",
      "scale:  0.9\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.434\n",
      "scale:  0.0\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_gb_lsun : 0.063\n",
      "scale:  0.1\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_gb_lsun : 0.063\n",
      "scale:  0.2\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_gb_lsun : 0.066\n",
      "scale:  0.30000000000000004\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_gb_lsun : 0.072\n",
      "scale:  0.4\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_gb_lsun : 0.085\n",
      "scale:  0.5\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_gb_lsun : 0.111\n",
      "scale:  0.6000000000000001\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_gb_lsun : 0.155\n",
      "scale:  0.7000000000000001\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_gb_lsun : 0.223\n",
      "scale:  0.8\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_gb_lsun : 0.312\n",
      "scale:  0.9\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_gb_lsun : 0.415\n",
      "scale:  0.0\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_20p_lsun : 0.079\n",
      "scale:  0.1\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_20p_lsun : 0.079\n",
      "scale:  0.2\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_20p_lsun : 0.082\n",
      "scale:  0.30000000000000004\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_20p_lsun : 0.088\n",
      "scale:  0.4\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_20p_lsun : 0.103\n",
      "scale:  0.5\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_20p_lsun : 0.131\n",
      "scale:  0.6000000000000001\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_20p_lsun : 0.175\n",
      "scale:  0.7000000000000001\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_20p_lsun : 0.238\n",
      "scale:  0.8\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_20p_lsun : 0.316\n",
      "scale:  0.9\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_20p_lsun : 0.404\n",
      "scale:  0.0\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_4px_lsun : 0.072\n",
      "scale:  0.1\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_4px_lsun : 0.072\n",
      "scale:  0.2\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_4px_lsun : 0.075\n",
      "scale:  0.30000000000000004\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_4px_lsun : 0.081\n",
      "scale:  0.4\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_4px_lsun : 0.094\n",
      "scale:  0.5\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_4px_lsun : 0.119\n",
      "scale:  0.6000000000000001\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_4px_lsun : 0.161\n",
      "scale:  0.7000000000000001\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_4px_lsun : 0.223\n",
      "scale:  0.8\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_4px_lsun : 0.304\n",
      "scale:  0.9\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_4px_lsun : 0.399\n",
      "scale:  0.0\n",
      "3000\n",
      "fmnist_svd20_lsun : 0.147\n",
      "scale:  0.1\n",
      "3000\n",
      "fmnist_svd20_lsun : 0.147\n",
      "scale:  0.2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f39163c38a24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scale: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0maurocTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestlists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-91862a361ba2>\u001b[0m in \u001b[0;36maurocTest\u001b[0;34m(train_dist, blurtype, testlist, plot, cs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0moutputs2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mid_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moutputs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m99\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('ID_blurtype_OOD : aurocScore')\n",
    "for k in models:\n",
    "    for b in models[k]:\n",
    "        for i in range(10):\n",
    "            print('scale: ', 0.1*i)\n",
    "            aurocTest(k, b, testlists[k], plot=False, cs=0.1*i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_blurtype_OOD : aurocScore\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd22_celeba : 0.691\n",
      "10000\n",
      "cifar10_svd22_trafficsign : 0.525\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz to ../data/KMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8cfe90df724df7b72d4a0a803ba4a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/KMNIST/raw/train-images-idx3-ubyte.gz to ../data/KMNIST/raw\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz to ../data/KMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c749cd1067294d6c91612ce8c163028d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/KMNIST/raw/train-labels-idx1-ubyte.gz to ../data/KMNIST/raw\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz to ../data/KMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423b6a57afd342bea6cf017b42a0185a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/KMNIST/raw/t10k-images-idx3-ubyte.gz to ../data/KMNIST/raw\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz to ../data/KMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dca00cb07f044adb557037345f28366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/KMNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/KMNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "cifar10_svd22_kmnist : 0.977\n",
      "Downloading https://github.com/brendenlake/omniglot/raw/master/python/images_evaluation.zip to ../data/omniglot-py/images_evaluation.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c26bc117114ca9bbab14c4a8529ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/omniglot-py/images_evaluation.zip to ../data/omniglot-py\n",
      "10000\n",
      "cifar10_svd22_omniglot : 0.966\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_celeba : 0.693\n",
      "10000\n",
      "cifar10_svd28_trafficsign : 0.488\n",
      "10000\n",
      "cifar10_svd28_kmnist : 0.969\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_svd28_omniglot : 0.940\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_celeba : 0.694\n",
      "10000\n",
      "cifar10_dct28_trafficsign : 0.510\n",
      "10000\n",
      "cifar10_dct28_kmnist : 0.972\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_dct28_omniglot : 0.941\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_celeba : 0.691\n",
      "10000\n",
      "cifar10_gb_trafficsign : 0.725\n",
      "10000\n",
      "cifar10_gb_kmnist : 0.999\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_gb_omniglot : 1.000\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_celeba : 0.795\n",
      "10000\n",
      "cifar10_20p_trafficsign : 0.763\n",
      "10000\n",
      "cifar10_20p_kmnist : 0.997\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_20p_omniglot : 1.000\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_4px_celeba : 0.673\n",
      "10000\n",
      "cifar10_4px_trafficsign : 0.767\n",
      "10000\n",
      "cifar10_4px_kmnist : 0.999\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "cifar10_4px_omniglot : 0.967\n",
      "3000\n",
      "fmnist_svd20_lsun : 0.196\n",
      "3000\n",
      "fmnist_svd24_lsun : 0.304\n",
      "3000\n",
      "fmnist_dct28_lsun : 0.759\n",
      "3000\n",
      "fmnist_gb_lsun : 0.009\n",
      "3000\n",
      "fmnist_20p_lsun : 0.367\n",
      "3000\n",
      "fmnist_4px_lsun : 0.023\n"
     ]
    }
   ],
   "source": [
    "print('ID_blurtype_OOD : aurocScore')\n",
    "for k in models:\n",
    "    for b in models[k]:\n",
    "        aurocTest(k, b, testlists[k], plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_blurtype_OOD : aurocScore\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd22_lsun : 0.577\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_svd28_lsun : 0.574\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_dct28_lsun : 0.573\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_gb_lsun : 0.523\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_20p_lsun : 0.495\n",
      "Files already downloaded and verified\n",
      "3000\n",
      "cifar10_4px_lsun : 0.497\n",
      "3000\n",
      "fmnist_svd20_lsun : 0.196\n",
      "3000\n",
      "fmnist_svd24_lsun : 0.304\n",
      "3000\n",
      "fmnist_dct28_lsun : 0.759\n",
      "3000\n",
      "fmnist_gb_lsun : 0.009\n",
      "3000\n",
      "fmnist_20p_lsun : 0.367\n",
      "3000\n",
      "fmnist_4px_lsun : 0.023\n"
     ]
    }
   ],
   "source": [
    "print('ID_blurtype_OOD : aurocScore')\n",
    "for k in models:\n",
    "    for b in models[k]:\n",
    "        aurocTest(k, b, testlists[k], plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_color_scale(x):\n",
    "    x = x * 255\n",
    "    m = torch.mean(x)\n",
    "    x = torch.clamp((x - m) * cs + m, 0, 255) // 1\n",
    "    x = x / 255\n",
    "    return x\n",
    "\n",
    "preprocess1 = [transforms.Normalize((0.48,), (0.2,))]\n",
    "preprocess3 = [transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]\n",
    "\n",
    "class Constant(data.Dataset):\n",
    "    def __init__(self, number=10000, transform=None):\n",
    "        super(Constant, self).__init__()\n",
    "        self.number = number\n",
    "        self.total_data = torch.randint(0, 256, (number, 3, 1, 1))\n",
    "        self.transform = transform\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.number\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        print(self.total_data[0])\n",
    "        data = self.total_data[index].float()\n",
    "        data = data.repeat(1, 32, 32) / 255\n",
    "        print(data[0])\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = Constant(transform=preprocess3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 15]],\n",
      "\n",
      "        [[185]],\n",
      "\n",
      "        [[209]]])\n",
      "tensor([[0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "        [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "        [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "        ...,\n",
      "        [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "        [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588],\n",
      "        [0.0588, 0.0588, 0.0588,  ..., 0.0588, 0.0588, 0.0588]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.1383, -2.1383, -2.1383,  ..., -2.1383, -2.1383, -2.1383],\n",
       "         [-2.1383, -2.1383, -2.1383,  ..., -2.1383, -2.1383, -2.1383],\n",
       "         [-2.1383, -2.1383, -2.1383,  ..., -2.1383, -2.1383, -2.1383],\n",
       "         ...,\n",
       "         [-2.1383, -2.1383, -2.1383,  ..., -2.1383, -2.1383, -2.1383],\n",
       "         [-2.1383, -2.1383, -2.1383,  ..., -2.1383, -2.1383, -2.1383],\n",
       "         [-2.1383, -2.1383, -2.1383,  ..., -2.1383, -2.1383, -2.1383]],\n",
       "\n",
       "        [[ 1.2201,  1.2201,  1.2201,  ...,  1.2201,  1.2201,  1.2201],\n",
       "         [ 1.2201,  1.2201,  1.2201,  ...,  1.2201,  1.2201,  1.2201],\n",
       "         [ 1.2201,  1.2201,  1.2201,  ...,  1.2201,  1.2201,  1.2201],\n",
       "         ...,\n",
       "         [ 1.2201,  1.2201,  1.2201,  ...,  1.2201,  1.2201,  1.2201],\n",
       "         [ 1.2201,  1.2201,  1.2201,  ...,  1.2201,  1.2201,  1.2201],\n",
       "         [ 1.2201,  1.2201,  1.2201,  ...,  1.2201,  1.2201,  1.2201]],\n",
       "\n",
       "        [[ 1.8563,  1.8563,  1.8563,  ...,  1.8563,  1.8563,  1.8563],\n",
       "         [ 1.8563,  1.8563,  1.8563,  ...,  1.8563,  1.8563,  1.8563],\n",
       "         [ 1.8563,  1.8563,  1.8563,  ...,  1.8563,  1.8563,  1.8563],\n",
       "         ...,\n",
       "         [ 1.8563,  1.8563,  1.8563,  ...,  1.8563,  1.8563,  1.8563],\n",
       "         [ 1.8563,  1.8563,  1.8563,  ...,  1.8563,  1.8563,  1.8563],\n",
       "         [ 1.8563,  1.8563,  1.8563,  ...,  1.8563,  1.8563,  1.8563]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
