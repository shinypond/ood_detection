{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d914db8-ce51-40ac-a11f-81cd73736c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x210b284b030>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd() + '/core')\n",
    "sys.path.append(os.getcwd() + '/core/train_GLOW') \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "\n",
    "import core.config as config\n",
    "from core.model_loader import load_pretrained_VAE\n",
    "from core.data_loader import TRAIN_loader, TEST_loader\n",
    "from core.custom_loss import KL_div, VAE_loss_pixel\n",
    "from core.fisher_utils_VAE import Calculate_fisher_VAE, Calculate_score_VAE, AUTO_VAE\n",
    "from core.fisher_utils_VAE import Calculate_fisher_VAE_ekfac, Calculate_score_VAE_ekfac\n",
    "from core.visualize import plot_hist, AUROC, plot_scores_all_layers\n",
    "\n",
    "# fix a random seed\n",
    "seed = 2021\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d81c61c1-024b-4edf-bbe9-057a2f55cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = config.VAE_fmnist\n",
    "netE, netG = load_pretrained_VAE(option=opt.train_dist, num=1, ngf=32, nz=100, beta=1, augment='hflip', epoch=100)\n",
    "netE.eval()\n",
    "netG.eval()\n",
    "modules = [] # Write the name of modules you want to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb0566a-1c8d-49ef-bef7-fd472ce576da",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate A, B:   0%|                                                                              | 0/60000 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(0): Conv2d(128, 100, kernel_size=(4, 4), stride=(1, 1))\n",
      "(1): Conv2d(128, 100, kernel_size=(4, 4), stride=(1, 1))\n",
      "(2): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "(3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "(4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shinypond\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "Calculate A, B:  17%|██████████▉                                                       | 9999/60000 [00:52<04:20, 192.02step/s]\n",
      "Calculate Fisher Inverse:  17%|█████████▎                                              | 9999/60000 [00:57<04:47, 173.78step/s]\n",
      "Calculate Score of fmnist(train):  17%|███████▉                                        | 9999/60000 [01:04<05:20, 155.87step/s]\n",
      "Calculate Score of fmnist:  50%|███████████████████████████▍                           | 4999/10000 [00:32<00:32, 154.62step/s]\n",
      "Calculate Score of overall:   0%|                                                                  | 0/10000 [00:00<?, ?step/s]C:\\Users\\shinypond\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "Calculate Score of overall:   0%|                                                        | 15/10000 [00:00<01:08, 145.97step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Inference Time : 0.0064710105999999995 seconds\n",
      "Average #Images Processed : 154.53536731959613 Images\n",
      "fmnist/fmnist 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Score of overall:  50%|██████████████████████████▉                           | 4999/10000 [00:34<00:34, 146.25step/s]\n",
      "Calculate A, B:   0%|                                                                              | 0/60000 [00:00<?, ?step/s]C:\\Users\\shinypond\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "Calculate A, B:   0%|                                                                    | 15/60000 [00:00<06:58, 143.24step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmnist/overall 0.99867764\n",
      "Now 2021-05-27 13:55:48.936185 Elapsed Time 0:04:00.975401\n",
      "[0.99867764]\n",
      "1\n",
      "(0): Conv2d(128, 100, kernel_size=(4, 4), stride=(1, 1))\n",
      "(1): Conv2d(128, 100, kernel_size=(4, 4), stride=(1, 1))\n",
      "(2): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "(3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "(4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate A, B:  17%|██████████▉                                                       | 9999/60000 [01:01<05:09, 161.30step/s]\n",
      "Calculate Fisher Inverse:  17%|█████████▎                                              | 9999/60000 [01:09<05:45, 144.58step/s]\n",
      "Calculate Score of fmnist(train):  17%|███████▉                                        | 9999/60000 [01:15<06:16, 132.84step/s]\n",
      "Calculate Score of fmnist:  50%|███████████████████████████▍                           | 4999/10000 [00:37<00:37, 132.56step/s]\n",
      "Calculate Score of overall:   0%|                                                                  | 0/10000 [00:00<?, ?step/s]C:\\Users\\shinypond\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "Calculate Score of overall:   0%|                                                        | 12/10000 [00:00<01:23, 119.16step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Inference Time : 0.0075471717999999995 seconds\n",
      "Average #Images Processed : 132.4999650862592 Images\n",
      "fmnist/fmnist 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Score of overall:  50%|██████████████████████████▉                           | 4999/10000 [00:40<00:40, 123.36step/s]\n",
      "Calculate A, B:   0%|                                                                              | 0/60000 [00:00<?, ?step/s]C:\\Users\\shinypond\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "Calculate A, B:   0%|                                                                    | 13/60000 [00:00<08:03, 124.17step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmnist/overall 0.9984162799999999\n",
      "Now 2021-05-27 14:00:34.030957 Elapsed Time 0:08:46.070173\n",
      "[0.99867764, 0.9984162799999999]\n",
      "2\n",
      "(0): Conv2d(128, 100, kernel_size=(4, 4), stride=(1, 1))\n",
      "(1): Conv2d(128, 100, kernel_size=(4, 4), stride=(1, 1))\n",
      "(2): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "(3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "(4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate A, B:  17%|██████████▉                                                       | 9999/60000 [01:13<06:05, 136.73step/s]\n",
      "Calculate Fisher Inverse:  17%|█████████▎                                              | 9999/60000 [01:20<06:40, 124.82step/s]\n",
      "Calculate Score of fmnist(train):  17%|███████▉                                        | 9999/60000 [01:25<07:09, 116.35step/s]\n",
      "Calculate Score of fmnist:  50%|███████████████████████████▍                           | 4999/10000 [00:43<00:43, 116.13step/s]\n",
      "Calculate Score of overall:   0%|                                                                  | 0/10000 [00:00<?, ?step/s]C:\\Users\\shinypond\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "Calculate Score of overall:   0%|                                                        | 12/10000 [00:00<01:30, 110.42step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Inference Time : 0.0086140692 seconds\n",
      "Average #Images Processed : 116.08915331211874 Images\n",
      "fmnist/fmnist 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate Score of overall:  17%|█████████▏                                            | 1692/10000 [00:15<01:14, 111.59step/s]"
     ]
    }
   ],
   "source": [
    "#results = {}\n",
    "start = datetime.now()\n",
    "for sampling in [10000]:\n",
    "    result = []\n",
    "    for i in range(30):\n",
    "        torch.cuda.empty_cache()\n",
    "        print(i)\n",
    "        auroc = {}\n",
    "        SCOREs = {}\n",
    "\n",
    "        U_A, U_B, S, mean, std = Calculate_fisher_VAE_ekfac(netE, netG, opt, select_modules=modules, max_iter=sampling, seed=2021+i+sampling)\n",
    "\n",
    "        for ood in [opt.train_dist, 'overall']:\n",
    "            score = Calculate_score_VAE_ekfac(netE, netG, opt, U_A, U_B, S, ood, max_iter=5000, seed=2021+i+sampling)\n",
    "            temp = []\n",
    "            for name in score.keys():\n",
    "                a = np.array(score[name])\n",
    "                a = (a - mean[name]) / std[name]  \n",
    "                temp.append(a) \n",
    "            score = np.max(np.concatenate(temp, 1), 1)\n",
    "            SCOREs[ood] = score\n",
    "            args = [SCOREs[opt.train_dist], SCOREs[ood]]\n",
    "            labels = [opt.train_dist, ood]\n",
    "            auroc[ood] = AUROC(*args, labels=labels, verbose=False)\n",
    "            print(f'{opt.train_dist}/{ood} {auroc[ood]}')\n",
    "        result.append(auroc['overall'])\n",
    "        print(f'Now {datetime.now()} Elapsed Time {datetime.now() - start}')\n",
    "        print(result)\n",
    "        np.save(f'./temp/{opt.train_dist}_sampling_{sampling}.npy', np.array(result))\n",
    "    #results[sampling] = result\n",
    "#df = pd.DataFrame(results)\n",
    "#df.to_csv(f'./temp/{opt.train_dist}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5217a045-57ca-4a3f-b0bb-77d36149119e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
